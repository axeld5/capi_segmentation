{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_nccl_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnccl\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnccl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\nccl.py:45\u001b[0m, in \u001b[0;36mversion\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m():\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    Returns the version of the NCCL.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m        tuple: The version information of the NCCL.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     ver \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nccl_version\u001b[49m()\n\u001b[0;32m     46\u001b[0m     major \u001b[38;5;241m=\u001b[39m ver \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     47\u001b[0m     minor \u001b[38;5;241m=\u001b[39m (ver \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m16\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m65535\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_nccl_version'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.cuda.nccl\n",
    "\n",
    "print(torch.cuda.nccl.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\axeld/.cache\\torch\\hub\\facebookresearch_capi_main\n",
      "Can't import sklearnex. If installed, that speeds up scikit-learn 10-100x\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "capi_vitl14_lvd = torch.hub.load('facebookresearch/capi:main', 'capi_vitl14_lvd')\n",
    "\n",
    "# Simply call the models to encode an image\n",
    "img = torch.zeros(1, 3, 224, 224)  # example img, replace with your stuff\n",
    "global_repr, registers, feature_map = capi_vitl14_lvd(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import logging\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from collections import defaultdict, deque\n",
    "from collections.abc import Callable, Iterable, Sequence\n",
    "from functools import partial, reduce\n",
    "from pathlib import Path\n",
    "from typing import Any, Literal\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics, sklearn.linear_model\n",
    "import torch\n",
    "import torch.amp\n",
    "import torch.distributed\n",
    "from jaxtyping import Float, Int, Num\n",
    "from torch import Tensor, nn\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def accuracy(y_true, y_pred, ignore_labels: Sequence[int]):\n",
    "    gt = y_true.flatten().cpu().numpy()\n",
    "    pred = y_pred.flatten().cpu().numpy()\n",
    "    mask = ~np.isin(gt, ignore_labels)\n",
    "    return float(np.mean((gt[mask] == pred[mask]).astype(float)))\n",
    "\n",
    "\n",
    "def mIoU(y_true, y_pred, ignore_labels: Sequence[int]):\n",
    "    gt = y_true.flatten().cpu().numpy()\n",
    "    pred = y_pred.flatten().cpu().numpy()\n",
    "    mask = ~np.isin(gt, ignore_labels)\n",
    "    return float(sklearn.metrics.jaccard_score(gt[mask], pred[mask], average=\"macro\"))\n",
    "\n",
    "\n",
    "metrics_dict = {\n",
    "    \"mIoU\": mIoU,\n",
    "    \"acc\": accuracy,\n",
    "}\n",
    "\n",
    "class MetricLogger:\n",
    "    def __init__(self, delimiter: str = \"  \", output_file: str | Path | None = None):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "        if isinstance(output_file, str):\n",
    "            output_file = Path(output_file)\n",
    "        self.output_file = output_file\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __getattr__(self, attr):\n",
    "        if attr in self.meters:\n",
    "            return self.meters[attr]\n",
    "        if attr in self.__dict__:\n",
    "            return self.__dict__[attr]\n",
    "        raise AttributeError(f\"'{type(self).__name__}' object has no attribute '{attr}'\")\n",
    "\n",
    "    def __str__(self):\n",
    "        loss_str = []\n",
    "        for name, meter in self.meters.items():\n",
    "            loss_str.append(f\"{name}: {meter!s}\")\n",
    "        return self.delimiter.join(loss_str)\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        for meter in self.meters.values():\n",
    "            meter.synchronize_between_processes()\n",
    "\n",
    "    def add_meter(self, name, meter):\n",
    "        self.meters[name] = meter\n",
    "\n",
    "    def dump_in_output_file(self, iteration, iter_time, data_time):\n",
    "        if self.output_file is None or torch.distributed.get_rank() != 0:\n",
    "            return\n",
    "        dict_to_dump = {\n",
    "            \"iteration\": iteration,\n",
    "            \"iter_time\": iter_time,\n",
    "            \"data_time\": data_time,\n",
    "        }\n",
    "        dict_to_dump.update({k: v.median for k, v in self.meters.items()})\n",
    "        with self.output_file.open(\"a\") as f:\n",
    "            f.write(json.dumps(dict_to_dump) + \"\\n\")\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=None, n_iterations=None, start_iteration=0):\n",
    "        i = start_iteration\n",
    "        if not header:\n",
    "            header = \"\"\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        iter_time = SmoothedValue(fmt=\"{avg:.6f}\")\n",
    "        data_time = SmoothedValue(fmt=\"{avg:.6f}\")\n",
    "\n",
    "        if n_iterations is None:\n",
    "            n_iterations = len(iterable)\n",
    "\n",
    "        space_fmt = \":\" + str(len(str(n_iterations))) + \"d\"\n",
    "\n",
    "        log_list = [\n",
    "            header,\n",
    "            \"[{0\" + space_fmt + \"}/{1}]\",\n",
    "            \"eta: {eta}\",\n",
    "            \"{meters}\",\n",
    "            \"time: {time}\",\n",
    "            \"data: {data}\",\n",
    "        ]\n",
    "        if torch.cuda.is_available():\n",
    "            log_list += [\"max mem: {memory:.0f}MB\"]\n",
    "\n",
    "        log_msg = self.delimiter.join(log_list)\n",
    "        if i < n_iterations:\n",
    "            for obj in iterable:\n",
    "                data_time.update(time.time() - end)\n",
    "                yield obj\n",
    "                iter_time.update(time.time() - end)\n",
    "                if i % print_freq == 0 or i == n_iterations - 1:\n",
    "                    self.synchronize_between_processes()\n",
    "                    self.dump_in_output_file(iteration=i, iter_time=iter_time.avg, data_time=data_time.avg)\n",
    "                    eta_seconds = iter_time.global_avg * (n_iterations - i)\n",
    "                    eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                    if torch.cuda.is_available():\n",
    "                        logger.info(\n",
    "                            log_msg.format(\n",
    "                                i,\n",
    "                                n_iterations,\n",
    "                                eta=eta_string,\n",
    "                                meters=str(self),\n",
    "                                time=str(iter_time),\n",
    "                                data=str(data_time),\n",
    "                                memory=torch.cuda.max_memory_allocated() / 1024.0 / 1024.0,\n",
    "                            ),\n",
    "                        )\n",
    "                    else:\n",
    "                        logger.info(\n",
    "                            log_msg.format(\n",
    "                                i,\n",
    "                                n_iterations,\n",
    "                                eta=eta_string,\n",
    "                                meters=str(self),\n",
    "                                time=str(iter_time),\n",
    "                                data=str(data_time),\n",
    "                            ),\n",
    "                        )\n",
    "                i += 1\n",
    "                end = time.time()\n",
    "                if i >= n_iterations:\n",
    "                    break\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        logger.info(f\"{header} Total time: {total_time_str} ({total_time / n_iterations:.6f} s / it)\")\n",
    "\n",
    "def to_tensor(x: Tensor | float | int) -> Tensor:\n",
    "    if isinstance(x, Tensor):\n",
    "        return x\n",
    "    return torch.tensor(x)\n",
    "\n",
    "class SmoothedValue:\n",
    "    \"\"\"Track a series of values and provide access to smoothed values over a\n",
    "    window or the global series average.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, window_size=20, fmt=None):\n",
    "        if fmt is None:\n",
    "            fmt = \"{median:.4f} ({global_avg:.4f})\"\n",
    "        self.window_size = window_size\n",
    "        self.deque: deque[Tensor | float | int] = deque(maxlen=window_size)\n",
    "        self.total: Tensor | float | int = 0.0\n",
    "        self.count: int = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value: Tensor | float | int):\n",
    "        self.deque.append(value)\n",
    "        self.count += 1\n",
    "        self.total += value\n",
    "\n",
    "    def synchronize_between_processes(self):\n",
    "        \"\"\"Distributed synchronization of the metric\"\"\"\n",
    "        if not torch.distributed.is_initialized():\n",
    "            return\n",
    "        logger.debug(\"Synchronizing values\")\n",
    "        count = to_tensor(self.count).to(dtype=torch.float64, device=\"cuda\").reshape(1)\n",
    "        total = to_tensor(self.total).to(dtype=torch.float64, device=\"cuda\").reshape(1)\n",
    "        tensor_deque = torch.tensor(list(self.deque), dtype=torch.float64, device=\"cuda\")\n",
    "        t = torch.cat([count, total, tensor_deque], dim=0)\n",
    "        torch.distributed.barrier()\n",
    "        torch.distributed.all_reduce(t, op=torch.distributed.ReduceOp.AVG)\n",
    "        self.count = int(t[0].cpu().item())\n",
    "        self.total = t[1]\n",
    "        self.deque = deque(list(t[2:]), maxlen=self.window_size)\n",
    "\n",
    "    @property\n",
    "    def median(self) -> float | int:\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().cpu().item()\n",
    "\n",
    "    @property\n",
    "    def avg(self) -> float | int:\n",
    "        d = torch.tensor(list(self.deque), dtype=torch.float32)\n",
    "        return d.mean().cpu().item()\n",
    "\n",
    "    @property\n",
    "    def global_avg(self) -> float | int:\n",
    "        return to_tensor(self.total).cpu().item() / self.count\n",
    "\n",
    "    @property\n",
    "    def max(self) -> float | int:\n",
    "        return torch.tensor(self.deque).max().cpu().item()\n",
    "\n",
    "    @property\n",
    "    def value(self) -> float | int:\n",
    "        v = self.deque[-1]\n",
    "        return to_tensor(v).cpu().item()\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(\n",
    "            median=self.median,\n",
    "            avg=self.avg,\n",
    "            global_avg=self.global_avg,\n",
    "            max=self.max,\n",
    "            value=self.value,\n",
    "        )\n",
    "\n",
    "class Classifier:\n",
    "    hparam_grids: dict[str, Iterable[Any]]\n",
    "    n_pixels_per_sample: int\n",
    "    label_dtype: torch.dtype\n",
    "    inference_bs: int\n",
    "    train_set_subsampling: int\n",
    "    ignore_labels: Sequence[int]\n",
    "\n",
    "    def fit(self, features: Float[Tensor, \"n d\"], labels: Int[Tensor, \"n l\"]) -> None:\n",
    "        self.unfit()\n",
    "        if self.train_set_subsampling > 1:\n",
    "            labels = labels[:: self.train_set_subsampling]\n",
    "            features = features[:: self.train_set_subsampling]\n",
    "        mask = torch.isin(labels.mode(dim=-1).values, torch.tensor(self.ignore_labels))\n",
    "        self._fit(features[~mask], labels[~mask])\n",
    "\n",
    "    def unfit(self) -> None:\n",
    "        pass\n",
    "\n",
    "    def upscale(self, labels: Int[Tensor, \"n\"]) -> Int[Tensor, \"n l\"]:  # noqa: F821\n",
    "        \"\"\"Convert from patch-level to pixel-level\"\"\"\n",
    "        return labels[:, None].expand(-1, self.n_pixels_per_sample)\n",
    "\n",
    "    def select_hparams(\n",
    "        self,\n",
    "        features_train: Float[Tensor, \"nt d\"],\n",
    "        labels_train: Int[Tensor, \"nt l\"],\n",
    "        features_val: Float[Tensor, \"nv d\"],\n",
    "        labels_val: Int[Tensor, \"nv l\"],\n",
    "        ignore_labels: Sequence[int],\n",
    "        metric_name: str = \"mIoU\",\n",
    "    ) -> dict[str, float]:\n",
    "        hparam_names, grids = zip(*self.hparam_grids.items(), strict=False)\n",
    "        hparam_grid = list(itertools.product(*grids))\n",
    "        metrics = {}\n",
    "        r = torch.distributed.get_rank()\n",
    "        n = torch.distributed.get_world_size()\n",
    "        rank_results: dict[int, float] = {}\n",
    "        if len(hparam_grid) > 1:\n",
    "            # split the grid among ranks\n",
    "            for hparam_idx, hparam_set in list(enumerate(hparam_grid))[r::n]:\n",
    "                logger.info(f\"Rank {r} testing hparam set {hparam_idx}/{len(hparam_grid)}\")\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "                for k, v in zip(hparam_names, hparam_set, strict=False):\n",
    "                    logger.info(f\"Setting {k}={v}\")\n",
    "                    setattr(self, k, v)\n",
    "                self.fit(features_train, labels_train)\n",
    "                preds = self.predict(features_val)\n",
    "                score = metrics_dict[metric_name](labels_val, preds, ignore_labels)\n",
    "                rank_results[hparam_idx] = score\n",
    "                logger.info(\n",
    "                    \"Tested \"\n",
    "                    + \"_\".join(f\"{k}={v}\" for k, v in zip(hparam_names, hparam_set, strict=False))\n",
    "                    + f\", {metric_name}={score:.3f}\",\n",
    "                )\n",
    "                self.unfit()\n",
    "                gc.collect()\n",
    "                torch.cuda.empty_cache()\n",
    "            torch.distributed.barrier()\n",
    "            gathered_results = [{} for _ in range(torch.distributed.get_world_size())]\n",
    "            torch.distributed.all_gather_object(gathered_results, rank_results)\n",
    "            all_results = reduce(lambda x, y: {**x, **y}, gathered_results)\n",
    "            best_hparam_idx, best_score = max(all_results.items(), key=lambda x: x[1])\n",
    "            best_hparam_set = hparam_grid[best_hparam_idx]\n",
    "            # log a bit\n",
    "            for idx, score in all_results.items():\n",
    "                hruid = f\"{metric_name}_\" + \"_\".join(\n",
    "                    f\"{k}={v}\" for k, v in zip(hparam_names, hparam_grid[idx], strict=True)\n",
    "                )\n",
    "                metrics[hruid] = score\n",
    "            logger.info(\n",
    "                \"Best hparam set: \"\n",
    "                + \"_\".join(f\"{k}={v}\" for k, v in zip(hparam_names, best_hparam_set, strict=True))\n",
    "                + f\" with {metric_name} {best_score:.3f}\",\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\"Grid is length 1, skipping hparam search\")\n",
    "            best_hparam_set = hparam_grid[0]\n",
    "        # set the new hparams\n",
    "        for k, v in zip(hparam_names, best_hparam_set, strict=False):\n",
    "            setattr(self, k, v)\n",
    "        return metrics\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def predict(self, features: Float[Tensor, \"n d\"]) -> Int[Tensor, \"n l\"]:\n",
    "        predictions = torch.zeros(features.shape[0], self.n_pixels_per_sample, dtype=self.label_dtype, device=\"cpu\")\n",
    "        for i in MetricLogger().log_every(\n",
    "            range(0, features.shape[0], self.inference_bs),\n",
    "            print_freq=10,\n",
    "            header=f\"{type(self).__name__} inference\",\n",
    "        ):\n",
    "            predictions[i : i + self.inference_bs] = self._predict_batch(features[i : i + self.inference_bs])\n",
    "            gc.collect()\n",
    "        return predictions\n",
    "\n",
    "    def _fit(self, features: Float[Tensor, \"n d\"], labels: Int[Tensor, \"n l\"]) -> None:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def _predict_batch(self, features: Float[Tensor, \"n d\"]) -> Int[Tensor, \"n l\"]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class KNNClassifier(Classifier):\n",
    "    num_neighbors: int\n",
    "    distance: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        inference_bs: int = 1024,\n",
    "        train_set_chunk_size: int | None = 262144,\n",
    "        train_set_subsampling: int = 1,\n",
    "        device: str = \"cuda\",\n",
    "        dtype: str = \"float32\",\n",
    "        num_neighbors: Sequence[int] = (1, 3, 10, 30),\n",
    "        distance: Sequence[str] = (\"cosine\", \"L2\"),\n",
    "        ignore_labels: Sequence[int] = (255,),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(device)\n",
    "        self.dtype = getattr(torch, dtype)\n",
    "        self.inference_bs = inference_bs\n",
    "        self.train_set_chunk_size = train_set_chunk_size\n",
    "        self.train_set_subsampling = train_set_subsampling\n",
    "        self.ignore_labels = ignore_labels\n",
    "        # try to make this grid divisible by 8 if possible\n",
    "        self.hparam_grids = {\n",
    "            \"num_neighbors\": num_neighbors,\n",
    "            \"distance\": distance,\n",
    "        }\n",
    "\n",
    "    def unfit(self):\n",
    "        if hasattr(self, \"train_X\"):\n",
    "            del self.train_X\n",
    "        if hasattr(self, \"train_y\"):\n",
    "            del self.train_y\n",
    "\n",
    "    def _fit(self, features: Float[Tensor, \"n d\"], labels: Int[Tensor, \"n l\"]) -> None:\n",
    "        self.train_X = features.to(self.dtype).to(self.device, non_blocking=True)\n",
    "        self.train_y = labels.to(self.device, non_blocking=True)\n",
    "        self.n_pixels_per_sample = labels.shape[-1]\n",
    "        self.label_dtype = labels.dtype\n",
    "\n",
    "    # @torch.compile\n",
    "    def _cdist(self, a: Float[Tensor, \"n d\"], b: Float[Tensor, \"m d\"]) -> Float[Tensor, \"n m\"]:\n",
    "        # WARN L1 and Linf are horribly slow\n",
    "        if self.distance == \"L2\":\n",
    "            return torch.cdist(a, b, p=2)\n",
    "        if self.distance == \"cosine\":\n",
    "            a = a / torch.norm(a, dim=-1)[:, None]\n",
    "            b = b / torch.norm(b, dim=-1)[:, None]\n",
    "            return 1 - a @ b.T\n",
    "        if self.distance == \"L1\":\n",
    "            return torch.cdist(a, b, p=1)\n",
    "        if self.distance == \"Linf\":\n",
    "            return torch.cdist(a, b, p=float(\"inf\"))\n",
    "        if self.distance == \"inner_product\":\n",
    "            return -a @ b.T\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @torch.compile(dynamic=True)\n",
    "    def _find_closest_chunk(\n",
    "        self,\n",
    "        queries: Float[Tensor, \"n d\"],\n",
    "        keys: Float[Tensor, \"m d\"],\n",
    "        values: Num[Tensor, \"m l\"],\n",
    "    ) -> tuple[Float[Tensor, \"n k\"], Num[Tensor, \"n k l\"]]:\n",
    "        dists = self._cdist(queries, keys)\n",
    "        # get top k closest neighbors\n",
    "        k = min(self.num_neighbors, dists.shape[-1])\n",
    "        distances, indices = torch.topk(dists, k, dim=-1, largest=False)\n",
    "        closest_values = torch.gather(\n",
    "            values,\n",
    "            0,\n",
    "            indices.flatten()[..., None].expand(indices.numel(), values.shape[1]),\n",
    "        ).reshape(*indices.shape, *values.shape[1:])\n",
    "        return distances, closest_values\n",
    "\n",
    "    def _predict_batch(self, features: Float[Tensor, \"n d\"]) -> Int[Tensor, \"n l\"]:\n",
    "        features = features.to(self.dtype).to(self.device, non_blocking=True)\n",
    "        chunk_size = self.train_set_chunk_size\n",
    "        if chunk_size is None:\n",
    "            chunk_size = self.train_X.shape[0]\n",
    "        aggregated_distances = []\n",
    "        aggregated_labels = []\n",
    "        for i in range(0, self.train_X.shape[0], chunk_size):\n",
    "            distances, closest_values = self._find_closest_chunk(\n",
    "                features,\n",
    "                self.train_X[i : i + chunk_size].to(self.dtype).to(self.device),\n",
    "                self.train_y[i : i + chunk_size].to(self.device),\n",
    "            )\n",
    "            aggregated_distances.append(distances.cpu())\n",
    "            aggregated_labels.append(closest_values.cpu())\n",
    "            del distances\n",
    "            del closest_values\n",
    "        _, aggregation_indices = torch.topk(\n",
    "            torch.cat(aggregated_distances, dim=1),\n",
    "            self.num_neighbors,\n",
    "            dim=1,\n",
    "            largest=False,\n",
    "        )\n",
    "        del aggregated_distances\n",
    "        neighbor_labels = torch.gather(\n",
    "            torch.cat(aggregated_labels, dim=1),\n",
    "            1,\n",
    "            aggregation_indices[..., None].expand(*aggregation_indices.shape, self.train_y.shape[1]),\n",
    "        )\n",
    "        del aggregated_labels\n",
    "        # get the most common label\n",
    "        return neighbor_labels.mode(dim=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import VisionDataset\n",
    "\n",
    "def dump_metrics(results_dict: dict, results_path: Path, cfg: Any) -> None:\n",
    "    if torch.distributed.get_rank() == 0:\n",
    "        logger.info(f\"Saving results to {results_path}\")\n",
    "        results_path.write_text(json.dumps({\"results\": results_dict, \"config\": cfg}))\n",
    "\n",
    "def all_gather_and_flatten(tensor_rank: Tensor):\n",
    "    tensor_all_ranks = torch.empty(\n",
    "        torch.distributed.get_world_size(),\n",
    "        *tensor_rank.shape,\n",
    "        dtype=tensor_rank.dtype,\n",
    "        device=tensor_rank.device,\n",
    "    )\n",
    "    torch.distributed.all_gather(list(tensor_all_ranks.unbind(0)), tensor_rank.contiguous())\n",
    "    return tensor_all_ranks.flatten(end_dim=1)\n",
    "\n",
    "class DatasetWithEnumeratedTargets(VisionDataset):\n",
    "    \"\"\"If pad_dataset is set, pads based on torch's DistributedSampler implementation, which\n",
    "    with drop_last=False pads the last batch to be a multiple of the world size.\n",
    "    https://github.com/pytorch/pytorch/blob/main/torch/utils/data/distributed.py#L91\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: VisionDataset, pad_dataset: bool = False, num_replicas: int | None = None):\n",
    "        self._dataset = dataset\n",
    "        self._size = len(self._dataset)\n",
    "        self._padded_size = self._size\n",
    "        self._pad_dataset = pad_dataset\n",
    "        if self._pad_dataset:\n",
    "            assert num_replicas is not None, \"num_replicas should be set if pad_dataset is True\"\n",
    "            self._padded_size = num_replicas * ((len(dataset) + num_replicas - 1) // num_replicas)\n",
    "\n",
    "    def __getitem__(self, index: int) -> tuple[Any, tuple[int, int]]:\n",
    "        image, target = self._dataset[index % self._size]\n",
    "        if index >= self._size:\n",
    "            assert self._pad_dataset\n",
    "            return image, (-1, target)\n",
    "        target = index if target is None else target\n",
    "        return image, (index, target)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._padded_size\n",
    "    \n",
    "\n",
    "import torch\n",
    "from torch.utils.data import IterableDataset\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from typing import Any, Iterator\n",
    "\n",
    "\n",
    "class IterableDatasetWithEnumeratedTargets(IterableDataset):\n",
    "    \"\"\"Iterable version of DatasetWithEnumeratedTargets.\n",
    "    Pads dataset if pad_dataset is True, ensuring the last batch is a multiple of world size.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dataset: VisionDataset, pad_dataset: bool = False, num_replicas: int | None = None):\n",
    "        super().__init__()\n",
    "        self._dataset = dataset\n",
    "        self._size = len(self._dataset)\n",
    "        self._pad_dataset = pad_dataset\n",
    "        self._padded_size = self._size\n",
    "\n",
    "        if self._pad_dataset:\n",
    "            assert num_replicas is not None, \"num_replicas should be set if pad_dataset is True\"\n",
    "            self._padded_size = num_replicas * ((len(dataset) + num_replicas - 1) // num_replicas)\n",
    "\n",
    "    def __iter__(self) -> Iterator[tuple[Any, tuple[int, int]]]:\n",
    "        index = 0\n",
    "        while index < self._padded_size:\n",
    "            image, target = self._dataset[index % self._size]\n",
    "            if index >= self._size:\n",
    "                assert self._pad_dataset\n",
    "                yield image, (-1, target)  # Padding case\n",
    "            else:\n",
    "                target = index if target is None else target\n",
    "                yield image, (index, target)\n",
    "            index += 1\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self._padded_size\n",
    "    \n",
    "    \n",
    "def make_data_loader(\n",
    "    *,\n",
    "    dataset,\n",
    "    batch_size: int=4,\n",
    "    num_workers: int=1,\n",
    "    shuffle: bool = True,\n",
    "    seed: int = 0,\n",
    "    sampler_advance: int = 0,\n",
    "    drop_last: bool = True,\n",
    "    persistent_workers: bool = False,\n",
    "    collate_fn: Callable[[list], Any] | None = None,\n",
    ") -> DataLoader:\n",
    "    logger.info(\"Using PyTorch data loader\")\n",
    "    if isinstance(dataset, torch.utils.data.IterableDataset):\n",
    "        logger.info(\"Dataset is iterable, not using a sampler\")\n",
    "        sampler = None\n",
    "    elif False:\n",
    "        logger.info(\"Using DistributedSampler\")\n",
    "        sampler = torch.utils.data.DistributedSampler(\n",
    "            dataset,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            drop_last=drop_last,\n",
    "        )\n",
    "    data_loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=drop_last,\n",
    "        persistent_workers=persistent_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    logger.info(f\"batch size: {batch_size}\")\n",
    "    try:\n",
    "        logger.info(f\"# of batches: {len(data_loader):,d}\")\n",
    "    except TypeError:  # data loader has no length\n",
    "        logger.info(\"infinite data loader\")\n",
    "    return data_loader\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def extract_features(\n",
    "    model: nn.Module,\n",
    "    dts_len: int,\n",
    "    dataset: VisionDataset,\n",
    "    *,\n",
    "    gather_on_cpu: bool = False,\n",
    ") -> tuple[Float[Tensor, \"len(dataset) ih iw d\"], Int[Tensor, \"len(dataset) ih iw ps**2\"]]:\n",
    "    \"\"\"Featurize the dataset.\"\"\"\n",
    "    bs = ih = iw = dim = 0\n",
    "    ps = model.patch_size\n",
    "    dataset_with_enumerated_targets = DatasetWithEnumeratedTargets(dataset)\n",
    "    iterabledataset_with_enumerated_targets = IterableDatasetWithEnumeratedTargets(dataset_with_enumerated_targets)\n",
    "    data_loader = make_data_loader(\n",
    "        dataset=iterabledataset_with_enumerated_targets,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    gather_device = torch.device(\"cpu\") if gather_on_cpu else torch.device(\"cuda\")\n",
    "    features, all_labels = None, None\n",
    "    for samples, (index, labels_rank) in MetricLogger().log_every(data_loader, 10, header=\"Extracting features\"):\n",
    "        samples = samples.cuda(non_blocking=True)\n",
    "        index = index.cuda(non_blocking=True)\n",
    "        _, _, featmap = model(samples)\n",
    "        bs, ih, iw, dim = featmap.shape\n",
    "        features_rank = featmap.reshape(bs * ih * iw, dim).float()\n",
    "        if len(labels_rank.shape) == 3:\n",
    "            # segmentation\n",
    "            labels_rank = einops.rearrange(\n",
    "                labels_rank,\n",
    "                \"bs (ih ph) (iw pw) -> (bs ih iw) (ph pw)\",\n",
    "                ih=ih,\n",
    "                iw=iw,\n",
    "                ph=ps,\n",
    "                pw=ps,\n",
    "            )\n",
    "        elif len(labels_rank.shape) == 1:\n",
    "            # classification\n",
    "            labels_rank = labels_rank[:, None, None].expand(bs, ih * iw, ps**2).flatten(0, 1)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        labels_rank = labels_rank.cuda(non_blocking=True)\n",
    "        sample_count = dts_len * ih * iw\n",
    "\n",
    "        # init storage feature matrix\n",
    "        if features is None or all_labels is None:\n",
    "            features = torch.zeros(\n",
    "                sample_count,\n",
    "                dim,\n",
    "                device=gather_device,\n",
    "                dtype=features_rank.dtype,\n",
    "            )\n",
    "            labels_shape = list(labels_rank.shape)\n",
    "            labels_shape[0] = sample_count\n",
    "            all_labels = torch.full(\n",
    "                labels_shape,\n",
    "                fill_value=-1,\n",
    "                device=gather_device,\n",
    "                dtype=labels_rank.dtype,\n",
    "            )\n",
    "            logger.info(f\"Storing features into tensor of shape {features.shape}\")\n",
    "\n",
    "        # share indexes, features and labels between processes\n",
    "        pos_rank = torch.arange(ih * iw, device=features_rank.device)[None, :].expand(bs, ih * iw).flatten()\n",
    "        index = index[:, None].expand(bs, ih * iw).flatten()\n",
    "        index = index * ih * iw + pos_rank.to(index.device).to(index.dtype)\n",
    "        index_all = all_gather_and_flatten(index).to(gather_device)\n",
    "        features_all_ranks = all_gather_and_flatten(features_rank).to(gather_device)\n",
    "        labels_all_ranks = all_gather_and_flatten(labels_rank).to(gather_device)\n",
    "\n",
    "        # update storage feature matrix\n",
    "        if len(index_all) > 0:\n",
    "            features.index_copy_(0, index_all, features_all_ranks)\n",
    "            all_labels.index_copy_(0, index_all, labels_all_ranks)\n",
    "\n",
    "    del data_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    assert features is not None and all_labels is not None\n",
    "    return features.reshape(dts_len, ih, iw, dim), all_labels.reshape(dts_len, ih, iw, ps**2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found image files: []\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "train_img_dir = \"./images/training_data\"  # Example\n",
    "train_mask_dir = \"./images/training_gt\"\n",
    "\n",
    "image_paths = sorted(glob.glob(os.path.join(train_img_dir, \"*.png\")))\n",
    "print(\"Found image files:\", image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Distributed package doesn't have NCCL built in",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 41\u001b[0m\n\u001b[0;32m     38\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCAL_RANK\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m     dist\u001b[38;5;241m.\u001b[39mbarrier(device_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCAL_RANK\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n\u001b[1;32m---> 41\u001b[0m \u001b[43menable_distributed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 37\u001b[0m, in \u001b[0;36menable_distributed\u001b[1;34m(set_cuda_current_device, backend, nccl_async_error_handling)\u001b[0m\n\u001b[0;32m     35\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTORCH_NCCL_ASYNC_ERROR_HANDLING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# \"TORCH_\" prefix added in PyTorch 2.2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSE_LIBUV\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 37\u001b[0m \u001b[43mdist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_process_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatetime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimedelta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseconds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCAL_RANK\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m=}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m dist\u001b[38;5;241m.\u001b[39mbarrier(device_ids\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mint\u001b[39m(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCAL_RANK\u001b[39m\u001b[38;5;124m\"\u001b[39m])])\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py:81\u001b[0m, in \u001b[0;36m_exception_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m     83\u001b[0m         msg_dict \u001b[38;5;241m=\u001b[39m _get_msg_dict(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\c10d_logger.py:95\u001b[0m, in \u001b[0;36m_time_logger.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: _P\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: _P\u001b[38;5;241m.\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _T:\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _WaitCounter(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpytorch.wait_counter.c10d.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mguard():\n\u001b[1;32m---> 95\u001b[0m         func_return \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func_return\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py:1721\u001b[0m, in \u001b[0;36minit_process_group\u001b[1;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[0m\n\u001b[0;32m   1717\u001b[0m         \u001b[38;5;66;03m# Use a PrefixStore to avoid accidental overrides of keys used by\u001b[39;00m\n\u001b[0;32m   1718\u001b[0m         \u001b[38;5;66;03m# different systems (e.g. RPC) in case the store is multi-tenant.\u001b[39;00m\n\u001b[0;32m   1719\u001b[0m         store \u001b[38;5;241m=\u001b[39m PrefixStore(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_pg\u001b[39m\u001b[38;5;124m\"\u001b[39m, store)\n\u001b[1;32m-> 1721\u001b[0m     default_pg, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_new_process_group_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpg_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1729\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1730\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1731\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_desc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdefault_pg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1732\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     _update_default_pg(default_pg)\n\u001b[0;32m   1735\u001b[0m _world\u001b[38;5;241m.\u001b[39mpg_group_ranks[GroupMember\u001b[38;5;241m.\u001b[39mWORLD] \u001b[38;5;241m=\u001b[39m {i: i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(GroupMember\u001b[38;5;241m.\u001b[39mWORLD\u001b[38;5;241m.\u001b[39msize())}  \u001b[38;5;66;03m# type: ignore[attr-defined, index]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\distributed\\distributed_c10d.py:1959\u001b[0m, in \u001b[0;36m_new_process_group_helper\u001b[1;34m(group_size, group_rank, global_ranks_in_group, backend, store, group_name, backend_options, timeout, pg_tag, device_id, group_desc)\u001b[0m\n\u001b[0;32m   1957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m backend_str \u001b[38;5;241m==\u001b[39m Backend\u001b[38;5;241m.\u001b[39mNCCL:\n\u001b[0;32m   1958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_nccl_available():\n\u001b[1;32m-> 1959\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDistributed package doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt have NCCL built in\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1960\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m backend_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1961\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1962\u001b[0m             backend_options, ProcessGroupNCCL\u001b[38;5;241m.\u001b[39mOptions\n\u001b[0;32m   1963\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected backend_options argument to be of type ProcessGroupNCCL.Options\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Distributed package doesn't have NCCL built in"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import socket\n",
    "import torch.distributed as dist\n",
    "\n",
    "def _get_available_port() -> int:\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        # A \"\" host address means INADDR_ANY i.e. binding to all interfaces.\n",
    "        # Note this is not compatible with IPv6.\n",
    "        s.bind((\"\", 0))\n",
    "        return s.getsockname()[1]\n",
    "\n",
    "@functools.lru_cache\n",
    "def enable_distributed(\n",
    "    *,\n",
    "    set_cuda_current_device: bool = True,\n",
    "    backend: str = \"nccl\",\n",
    "    nccl_async_error_handling: bool = False,\n",
    "):\n",
    "    if \"MASTER_ADDR\" not in os.environ:\n",
    "        # Environment is not set, assume single gpu\n",
    "        logger.info(\"Dist init for single-gpu training\")\n",
    "        os.environ[\"MASTER_ADDR\"] = \"127.0.0.1\"\n",
    "        os.environ[\"MASTER_PORT\"] = str(_get_available_port())\n",
    "        os.environ[\"RANK\"] = \"0\"\n",
    "        os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "        os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "        os.environ[\"LOCAL_WORLD_SIZE\"] = \"1\"\n",
    "        os.environ[\"USE_LIBUV\"] = \"0\"\n",
    "    else:\n",
    "        logger.info(\"Dist init from preset env\")\n",
    "    if set_cuda_current_device:\n",
    "        torch.cuda.set_device(int(os.environ[\"LOCAL_RANK\"]))\n",
    "    if nccl_async_error_handling:\n",
    "        os.environ[\"NCCL_ASYNC_ERROR_HANDLING\"] = \"1\"\n",
    "        os.environ[\"TORCH_NCCL_ASYNC_ERROR_HANDLING\"] = \"1\"  # \"TORCH_\" prefix added in PyTorch 2.2\n",
    "    os.environ[\"USE_LIBUV\"] = \"0\"\n",
    "    dist.init_process_group(backend=backend, timeout=datetime.timedelta(seconds=30))\n",
    "    logger.info(f\"{os.environ['LOCAL_RANK']=}\")\n",
    "    dist.barrier(device_ids=[int(os.environ[\"LOCAL_RANK\"])])\n",
    "\n",
    "enable_distributed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch._C' has no attribute '_nccl_version'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mnccl\u001b[38;5;241m.\u001b[39mis_available(torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda())\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnccl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mversion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\cuda\\nccl.py:45\u001b[0m, in \u001b[0;36mversion\u001b[1;34m()\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mversion\u001b[39m():\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    Returns the version of the NCCL.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m        tuple: The version information of the NCCL.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     ver \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nccl_version\u001b[49m()\n\u001b[0;32m     46\u001b[0m     major \u001b[38;5;241m=\u001b[39m ver \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[0;32m     47\u001b[0m     minor \u001b[38;5;241m=\u001b[39m (ver \u001b[38;5;241m>>\u001b[39m \u001b[38;5;241m16\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m65535\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch._C' has no attribute '_nccl_version'"
     ]
    }
   ],
   "source": [
    "torch.cuda.nccl.is_available(torch.randn(1).cuda())\n",
    "torch.cuda.nccl.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\axeld/.cache\\torch\\hub\\facebookresearch_capi_main\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 17432) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1251\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1251\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\queue.py:179\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_empty\u001b[38;5;241m.\u001b[39mwait(remaining)\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 248\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"for epoch in range(num_epochs):\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;124;03m        train_loss = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;124;03m        val_loss   = evaluate(model, val_loader, loss_fn, device)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m    print(f\"Test Loss: {test_loss:.4f}\")\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \u001b[38;5;124;03m    print(\"Model saved.\")\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 248\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 167\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    165\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mhub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacebookresearch/capi:main\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapi_vitl14_lvd\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    166\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m get_train_val_dataloaders(train_img_dir, train_mask_dir, batch_size, val_split)\n\u001b[1;32m--> 167\u001b[0m train_features, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_img_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m train_features \u001b[38;5;241m=\u001b[39m train_features\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    169\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m train_labels\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 146\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, dts_len, dataset, gather_on_cpu)\u001b[0m\n\u001b[0;32m    144\u001b[0m gather_device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m gather_on_cpu \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    145\u001b[0m features, all_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 146\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_rank\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mMetricLogger\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_every\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExtracting features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m    \u001b[49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msamples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 113\u001b[0m, in \u001b[0;36mMetricLogger.log_every\u001b[1;34m(self, iterable, print_freq, header, n_iterations, start_iteration)\u001b[0m\n\u001b[0;32m    111\u001b[0m log_msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter\u001b[38;5;241m.\u001b[39mjoin(log_list)\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m n_iterations:\n\u001b[1;32m--> 113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1458\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1458\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1459\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1410\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1409\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1410\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1411\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1412\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\axeld\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1264\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1263\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[1;32m-> 1264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1266\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[0;32m   1268\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 17432) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import v2 as T\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# 1. Custom Dataset\n",
    "# -------------------\n",
    "class ISICSegmentationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Expects:\n",
    "      - image_dir: folder with images like ISIC_XXXXXXX.jpg\n",
    "      - mask_dir:  folder with corresponding masks like ISIC_XXXXXXX_Segmentation.png\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, mask_dir, transform=None, target_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Look for .jpg images\n",
    "        self.image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.jpg\")))\n",
    "        if len(self.image_paths) == 0:\n",
    "            print(f\"[Warning] No .jpg images found in {image_dir}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path and corresponding mask path\n",
    "        img_path = self.image_paths[idx]\n",
    "        filename = os.path.basename(img_path)  # e.g. \"ISIC_0000000.jpg\"\n",
    "        mask_name = filename.replace(\".jpg\", \"_Segmentation.png\")\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "        \n",
    "        # Open images\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask  = Image.open(mask_path).convert(\"L\")  # single channel for mask\n",
    "        \n",
    "        # Resize both image and mask to target_size\n",
    "        image = image.resize(self.target_size, Image.BILINEAR)\n",
    "        mask  = mask.resize(self.target_size, Image.NEAREST)  # NEAREST preserves mask values\n",
    "        \n",
    "        # Convert to numpy arrays and scale\n",
    "        image = np.array(image, dtype=np.float32) / 255.0\n",
    "        mask  = np.array(mask, dtype=np.float32) / 255.0\n",
    "        \n",
    "        # Convert shape from H x W x C to C x H x W\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        mask  = np.expand_dims(mask, axis=0)\n",
    "        \n",
    "        # Optionally apply further transforms if provided\n",
    "        if self.transform:\n",
    "            image, mask = self.transform(image, mask)\n",
    "        \n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Create Datasets & Loaders\n",
    "# ----------------------------\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "def get_train_val_dataloaders(train_img_dir, train_mask_dir, batch_size=4, val_split=0.2):\n",
    "    full_dataset = ISICSegmentationDataset(train_img_dir, train_mask_dir)\n",
    "    total_samples = len(full_dataset)\n",
    "    val_size = int(total_samples * val_split)\n",
    "    train_size = total_samples - val_size\n",
    "    train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "# ------------------------\n",
    "# 3. Define the Model\n",
    "# ------------------------\n",
    "def create_model(num_classes=1):\n",
    "    # Example: U-Net with a ResNet34 encoder\n",
    "    # For a single class segmentation, set classes=1 and activation=None (we'll handle it in the loss)\n",
    "    model = smp.Unet(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=num_classes\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# 4. Training Loop\n",
    "# -----------------------\n",
    "def train_one_epoch(model, loader, loss_fn, optimizer, device=\"cuda\"):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for images, masks in loader:\n",
    "        images = images.to(device)\n",
    "        masks  = masks.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = loss_fn(outputs, masks)\n",
    "        \n",
    "        # Backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(loader)\n",
    "\n",
    "\n",
    "def evaluate(model, loader, loss_fn, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in loader:\n",
    "            images = images.to(device)\n",
    "            masks  = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, masks)\n",
    "            eval_loss += loss.item()\n",
    "    \n",
    "    return eval_loss / len(loader)\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# 5. Putting it all together\n",
    "# --------------------\n",
    "def main():\n",
    "    # Directories (update these paths with your own)\n",
    "    train_img_dir  = \"images/training_data\"\n",
    "    train_mask_dir = \"images/training_gt\"\n",
    "    test_img_dir   = \"images/test_data\"\n",
    "    test_mask_dir  = \"images/test_gt\"\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = 4\n",
    "    lr = 1e-4\n",
    "    num_epochs = 10\n",
    "    val_split = 0.2  # 20% of training data for validation\n",
    "    \n",
    "    # Device\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Get data loaders: split the training dataset into train and val\n",
    "    model = torch.hub.load('facebookresearch/capi:main', 'capi_vitl14_lvd')\n",
    "    train_loader, val_loader = get_train_val_dataloaders(train_img_dir, train_mask_dir, batch_size, val_split)\n",
    "    train_features, train_labels = extract_features(model, len(train_img_dir), train_loader)\n",
    "    train_features = train_features.flatten(0, -2)\n",
    "    train_labels = train_labels.flatten(0, -2)\n",
    "    val_features, val_labels = extract_features(model, int(len(train_img_dir)*val_split), val_loader)\n",
    "    val_features = val_features.flatten(0, -2)\n",
    "    val_labels = val_labels.flatten(0, -2)\n",
    "    test_dataset = ISICSegmentationDataset(test_img_dir, test_mask_dir)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_features, test_labels = extract_features(model, len(test_img_dir), test_loader)\n",
    "    test_features = test_features.flatten(0, -2)\n",
    "    test_labels = test_labels.flatten(0, -2)\n",
    "    model.cpu()\n",
    "    for k in list(model._parameters.keys()):\n",
    "            del model._parameters[k]\n",
    "    for k in list(model._modules.keys()):\n",
    "            del model._modules[k]\n",
    "    classifier = KNNClassifier(ignore_labels=(255,))\n",
    "    hparam_metrics = classifier.select_hparams(\n",
    "                train_features,\n",
    "                train_labels,\n",
    "                val_features,\n",
    "                val_labels,\n",
    "                (255,),\n",
    "            )\n",
    "    results_dict = {}\n",
    "    dump_predictions = True\n",
    "    dump_classifier = True\n",
    "    classifier_name = \"kNN\"\n",
    "    output_dir = \"\"\n",
    "    for k, v in hparam_metrics.items():\n",
    "                results_dict[f\"hparam_fitting.kNN.{k}\"] = v\n",
    "    if torch.distributed.get_rank() == 0:\n",
    "                classifier.fit(\n",
    "                    torch.cat([train_features, val_features]),\n",
    "                    torch.cat([train_labels, val_labels]),\n",
    "                )\n",
    "                preds = classifier.predict(test_features)\n",
    "                logger.info(f\"Predictions shape: {preds.shape}\")\n",
    "    if dump_predictions:\n",
    "                    torch.save(preds, Path(output_dir) / f\"preds_{classifier_name}.pth\")\n",
    "    for metric_name, metric in metrics_dict.items():\n",
    "                    result_name = f\"labels_{classifier_name}_{metric_name}\"\n",
    "                    results_dict[result_name] = float(metric(test_labels, preds, (255,)))\n",
    "                    logger.info(f\"{result_name}: {results_dict[result_name]:.4g}\")\n",
    "    if dump_classifier and hasattr(classifier, \"estimator\"):\n",
    "                    torch.save(\n",
    "                        {\n",
    "                            \"coef_\": torch.tensor(classifier.estimator.coef_),\n",
    "                            \"intercept_\": torch.tensor(classifier.estimator.intercept_),\n",
    "                        },\n",
    "                        Path(output_dir) / \"classifier.pth\",\n",
    "                    )\n",
    "            # dump partial results\n",
    "    metric_dumper = partial(dump_metrics, results_path=\"\", cfg={})\n",
    "    metric_dumper(results_dict)\n",
    "    torch.distributed.barrier()\n",
    "    del classifier\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Define loss & optimizer\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    # Training loop\n",
    "    \"\"\"for epoch in range(num_epochs):\n",
    "        train_loss = train_one_epoch(model, train_loader, loss_fn, optimizer, device)\n",
    "        val_loss   = evaluate(model, val_loader, loss_fn, device)\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}]\",\n",
    "              f\"Train Loss: {train_loss:.4f} |\",\n",
    "              f\"Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    # Save the fine-tuned model\n",
    "    torch.save(model.state_dict(), \"isic_unet_resnet34_finetuned.pth\")\n",
    "    test_loss = evaluate(model, test_loader, loss_fn, device)\n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(\"Model saved.\")\"\"\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
